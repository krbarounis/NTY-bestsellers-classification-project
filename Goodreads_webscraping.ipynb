{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Goodreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes Goodreads for books published in 2017 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import urllib.request\n",
    "import Goodreads_helper_functions as good\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_urls(url):\n",
    "    \"\"\"\n",
    "    get_book_urls(url):\n",
    "    Gets the url for each book's respective website on a Goodreads' list of best books\n",
    "    Params:\n",
    "        url: Goodreads' url which has a list of links for top books in a given year\n",
    "    Returns:\n",
    "        list of urls for each book\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "\n",
    "    # go through each page \n",
    "    for i in range(1,20):\n",
    "        new_url = str(url) + f'?page={i}'\n",
    "        open_url = urllib.request.urlopen(new_url)\n",
    "        soup = bs(open_url, 'html.parser')\n",
    "        soups = soup.find_all('div', {\"data-resource-type\":\"Book\"})\n",
    "\n",
    "    # iterate through each book on each page and grab its url\n",
    "        for i in range(len(soups)):\n",
    "            urls.append('https://goodreads.com' + soups[i].a['href'])\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the individual book urls from the master lists\n",
    "urls_2018 = get_book_urls('https://www.goodreads.com/list/show/119307.Best_Books_of_2018')\n",
    "urls_2017 = get_book_urls('https://www.goodreads.com/list/show/107026.Best_Books_of_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_info(urls):\n",
    "      \"\"\"\n",
    "    get_book_info(url):\n",
    "    Scrapes Goodreads' for a set of features for each book \n",
    "    Params:\n",
    "        urls: List of urls for each book to scrape \n",
    "    Returns:\n",
    "        list of dictionaries containing information for each book\n",
    "    \"\"\" \n",
    "    list_of_books = []\n",
    "    # iterate over the list of urls\n",
    "    for url in urls:\n",
    "        html_page = requests.get(url)\n",
    "        soup = bs(html_page.content, 'html.parser')\n",
    "    \n",
    "        book_dict = {}\n",
    "        # grab a bunch of information for each book and append to a list\n",
    "        book_dict['title'] = good.get_title(soup)\n",
    "        book_dict['ISBN'] = good.get_ISBN(soup)\n",
    "        book_dict['author'] = good.get_author(soup)\n",
    "        book_dict['series'] = good.get_series(soup)\n",
    "        book_dict['genre'] = good.get_genre(soup)\n",
    "        book_dict['rating'] = good.get_rating(soup)\n",
    "        book_dict['publish_date'] = good.get_publish_date(soup)\n",
    "        book_dict['publish_company'] = good.get_publishing_company(soup)\n",
    "        book_dict['number_of_pages'] = good.get_pages(soup)\n",
    "        book_dict['format'] = good.get_format(soup)\n",
    "    \n",
    "        list_of_books.append(book_dict)\n",
    "    return list_of_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the book data from each book url\n",
    "list_of_book_dicts_2018 = get_book_info(urls_2018)\n",
    "list_of_book_dicts_2017 = get_book_info(urls_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save!\n",
    "with open('Goodreads_books_2017.json','w') as book_file:\n",
    "    json.dump(list_of_book_dicts_2017, book_file)\n",
    "with open('Goodreads_books_2018.json','w') as book_file:\n",
    "    json.dump(list_of_book_dicts_2018, book_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
